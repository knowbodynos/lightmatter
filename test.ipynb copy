{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "from itertools import product\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "path = '/tmp/tensorflow/mnist/input_data'\n",
    "mnist = input_data.read_data_sets(path, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  0,  2],\n",
       "       [ 3, -4, -5],\n",
       "       [ 4,  0,  7]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array([[-1,0,2],[3,-4,-5],[4,0,7]])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = d_softmax_dz(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-211-b72a9f2f1043>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-211-b72a9f2f1043>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    q[:,*[0,1]\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "q[:,*[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.2968353e-06, 4.8300888e-09, 1.7768903e-09],\n",
       "       [1.6716609e-02, 2.6371390e-07, 9.7014926e-08],\n",
       "       [7.8612007e-04, 7.1684872e-07, 2.6371390e-07]], dtype=float32)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[:,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6371390e-07, 8.4595237e-04, 5.2968353e-06],\n",
       "       [1.4398292e-05, 1.3129543e-08, 4.8300888e-09],\n",
       "       [3.9138613e-05, 7.1684872e-07, 7.8612007e-04]], dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0,1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.11208477e-04, 8.45952347e-04, 6.25078935e-03],\n",
       "       [1.69914071e-02, 1.54941577e-05, 5.69998208e-06],\n",
       "       [4.61874331e-02, 8.45952347e-04, 9.27699394e-01]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(p) * (1 - np.exp(p[0,1]) / np.exp(p).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 0. ],\n",
       "       [0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. ]], dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 1. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0.5, 1. ]], dtype=float32)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p >= 0).astype(np.float32) - 0.5 * (p == 0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(product(*[range(i) for i in p.shape]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    \"\"\"Compute the rectified linear unit using z.\"\"\"\n",
    "    mask = (z > 0).astype(int)\n",
    "    return z * mask\n",
    "\n",
    "def d_relu_dz(z):\n",
    "    \"\"\"Compute the derivative of the rectified linear unit using z.\"\"\"\n",
    "    mask1 = (z >= 0).astype(np.float32)\n",
    "    mask2 = (z == 0).astype(np.float32)\n",
    "    mask3 = mask1 - 0.5 * mask2\n",
    "    result = np.zeros([z.shape[0]] + list(z.shape) * 2, dtype = np.float32)\n",
    "    for batch in range(z.shape[0]):\n",
    "        for z_inds in product(*[range(i) for i in z.shape[1:]]):\n",
    "            result_inds = tuple([batch] + list(z_inds) * 2)\n",
    "            z_inds = tuple([batch] + list(z_inds))\n",
    "            result[result_inds] = mask3[z_inds]\n",
    "    return result\n",
    "    \n",
    "def softmax(z):\n",
    "    \"\"\"Compute the softmax of z.\"\"\"\n",
    "    e_z = np.exp(z)\n",
    "    return e_z / e_z.sum()\n",
    "\n",
    "def d_softmax_dz(z):\n",
    "    \"\"\"Compute the derivative of the softmax of z.\"\"\"\n",
    "    e_z = np.exp(z)\n",
    "    softmax_z = softmax(z)\n",
    "    result = np.empty([z.shape[0]] + list(z.shape[1:]) * 2, dtype = np.float32)\n",
    "    for batch in range(z.shape[0]):\n",
    "        for z_inds in product(*[range(i) for i in z.shape[1:]]):\n",
    "            result_inds = tuple([batch] + list(z_inds) * 2)\n",
    "            z_inds = tuple([batch] + list(z_inds))\n",
    "            result[z_inds] = softmax_z[z_inds] * (e_z / e_z.sum())\n",
    "            result[result_inds] = softmax_z[z_inds] - result[result_inds]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    \"\"\"\n",
    "    Initialize weight matrices with truncated normal distribution with standard deviation of 0.1.\n",
    "\n",
    "    In general, shape = [filter_height, filter_width, in_channels, out_channels].\n",
    "    \"\"\"\n",
    "    stddev = 0.1\n",
    "    size = 1\n",
    "    for dim in shape:\n",
    "        size *= dim\n",
    "    return truncnorm.rvs(-2 * stddev, 2 * stddev, size=size).reshape(shape)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"\n",
    "    Initialize bias vectors with constant value of 0.1.\n",
    "\n",
    "    In general, shape = [out_channels].\n",
    "    \"\"\"\n",
    "    const = 0.1\n",
    "    return np.full(shape, const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2d:\n",
    "    def __init__(self, x, W, strides=[1, 1, 1, 1], padding='SAME'):\n",
    "        assert(x.shape[3] == W.shape[2])\n",
    "        self.x = x\n",
    "        self.W = W\n",
    "        self.strides = strides\n",
    "        self.batch_size = x.shape[0]\n",
    "        self.in_height = x.shape[1]\n",
    "        self.in_width = x.shape[2]\n",
    "        self.filter_height = W.shape[0]\n",
    "        self.filter_width = W.shape[1]\n",
    "        self.in_channels = W.shape[2]\n",
    "        self.out_channels = W.shape[3]\n",
    "        if padding == 'SAME':\n",
    "            self.out_height = ceil(float(self.in_height) / float(strides[1]))\n",
    "            self.out_width = ceil(float(self.in_width) / float(strides[2]))\n",
    "            if (self.in_height % strides[1] == 0):\n",
    "                pad_height = max(self.filter_height - strides[1], 0)\n",
    "            else:\n",
    "                pad_height = max(self.filter_height - (self.in_height % strides[1]), 0)\n",
    "            if (self.in_width % strides[2] == 0):\n",
    "                pad_width = max(self.filter_width - strides[2], 0)\n",
    "            else:\n",
    "                pad_width = max(self.filter_width - (self.in_width % strides[2]), 0)\n",
    "            self.pad_top = pad_height // 2\n",
    "            self.pad_bottom = pad_height - pad_top\n",
    "            self.pad_left = pad_width // 2\n",
    "            self.pad_right = pad_width - pad_left\n",
    "        elif padding == 'VALID':\n",
    "            self.out_height = ceil(float(self.in_height - self.filter_height + 1) / float(strides[1]))\n",
    "            self.out_width = ceil(float(self.in_width - self.filter_width + 1) / float(strides[2]))\n",
    "            self.pad_top = 0\n",
    "            self.pad_bottom = 0\n",
    "            self.pad_left = 0\n",
    "            self.pad_right = 0\n",
    "        self.x_pad = np.pad(x, [(0, 0), (pad_top, pad_bottom), (pad_left, pad_right), (0,0)], mode='constant')\n",
    "        self.y = np.empty([self.batch_size, self.out_height, self.out_width, self.out_channels], dtype = x.dtype)\n",
    "    \n",
    "    def eval(self):\n",
    "        self.y = np.empty([self.batch_size, self.out_height, self.out_width, self.out_channels], dtype = x.dtype)\n",
    "        for b in range(self.batch_size):\n",
    "            for i in range(self.out_height):\n",
    "                stride_i = self.strides[1] * i\n",
    "                for j in range(self.out_width):\n",
    "                    stride_j = self.strides[2] * j\n",
    "                    for k in range(self.out_channels):\n",
    "                        self.y[b, i, j, k] = (self.x_pad[b, stride_i:stride_i + self.filter_height, stride_j:stride_j + self.filter_width, :] * self.W[::-1, ::-1, :, k]).sum()\n",
    "        return self.y\n",
    "    \n",
    "    def ddx(self):\n",
    "        result = np.empty(self.y.shape + self.x_pad.shape[1:], dtype = np.float32)\n",
    "        for inds in product(*[range(i) for i in self.y.shape]):\n",
    "            max_ind_1 = self.filter_height + strides[1] * inds[1]\n",
    "            max_ind_2 = self.filter_width + strides[2] * inds[2]\n",
    "            result[inds] = self.W[max_ind_1:0:-1, max_ind_2:0:-1, :, inds[3]]\n",
    "        return result\n",
    "    \n",
    "    def ddw(self):\n",
    "        result = np.zeros(self.y.shape + self.W.shape, dtype = np.float32)\n",
    "        for inds in product(*[range(i) for i in self.y.shape]):\n",
    "            max_ind_1 = self.filter_height + strides[1] * inds[1]\n",
    "            max_ind_2 = self.filter_width + strides[2] * inds[2]\n",
    "            result[inds, :, : , :, inds[3]] = self.x_pad[inds[0], max_ind_1:0:-1, max_ind_2:0:-1, :]\n",
    "        return result\n",
    "\n",
    "\n",
    "class maxpool2d:\n",
    "    def __init__(self, x, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding='SAME'):\n",
    "        self.x = x\n",
    "        self.ksize = ksize\n",
    "        self.strides = strides\n",
    "        self.batch_size = x.shape[0]\n",
    "        self.in_height = x.shape[1]\n",
    "        self.in_width = x.shape[2]\n",
    "        self.in_channels = x.shape[3]\n",
    "        if padding == 'SAME':\n",
    "            self.out_height = ceil(float(self.in_height) / float(strides[1]))\n",
    "            self.out_width = ceil(float(self.in_width) / float(strides[2]))\n",
    "            if (self.in_height % strides[1] == 0):\n",
    "                pad_height = max(ksize[1] - strides[1], 0)\n",
    "            else:\n",
    "                pad_height = max(ksize[1] - (self.in_height % strides[1]), 0)\n",
    "            if (self.in_width % strides[2] == 0):\n",
    "                pad_width = max(ksize[2] - strides[2], 0)\n",
    "            else:\n",
    "                pad_width = max(ksize[2] - (self.in_width % strides[2]), 0)\n",
    "            self.pad_top = pad_height // 2\n",
    "            self.pad_bottom = pad_height - pad_top\n",
    "            self.pad_left = pad_width // 2\n",
    "            self.pad_right = pad_width - pad_left\n",
    "        elif padding == 'VALID':\n",
    "            self.out_height = ceil(float(self.in_height - ksize[1] + 1) / float(strides[1]))\n",
    "            self.out_width = ceil(float(self.in_width - ksize[2] + 1) / float(strides[2]))\n",
    "            self.pad_top = 0\n",
    "            self.pad_bottom = 0\n",
    "            self.pad_left = 0\n",
    "            self.pad_right = 0\n",
    "        self.x_pad = np.pad(x, [(0, 0), (pad_top, pad_bottom), (pad_left, pad_right), (0,0)], mode='constant')\n",
    "        self.mask = np.empty(self.x_pad.shape, dtype = int)\n",
    "        self.y = np.empty([self.batch_size, self.out_height, self.out_width, self.out_channels], dtype = x.dtype)\n",
    "    \n",
    "    def eval(self):\n",
    "        self.mask = np.empty(self.x_pad.shape, dtype = int)\n",
    "        self.y = np.empty([self.batch_size, self.out_height, self.out_width, self.out_channels], dtype = x.dtype)\n",
    "        for b in range(self.batch_size):\n",
    "            for i in range(self.out_height):\n",
    "                stride_i = self.strides[1] * i\n",
    "                for j in range(self.out_width):\n",
    "                    stride_j = self.strides[2] * j\n",
    "                    for k in range(self.out_channels):\n",
    "                        x_block = self.x_pad[b, stride_i:stride_i + self.ksize[1], stride_j:stride_j + self.ksize[2], k]\n",
    "                        max_val = x_block.max()\n",
    "                        self.y[b, i, j, k] = max_val\n",
    "                        self.mask[b, stride_i:stride_i + self.ksize[1], stride_j:stride_j + self.ksize[2], k] = (x_block == max_val).astype(int)\n",
    "        return self.y\n",
    "\n",
    "    \n",
    "class flatten:\n",
    "    def __init__(self, x):\n",
    "        \"\"\"Flatten tensor to shape [batch_size, x_height * x_width * in_channels].\"\"\"\n",
    "        self.x = x\n",
    "        self.batch_size = x.shape[0]\n",
    "        size = 1\n",
    "        for dim in x.shape[1:]:\n",
    "            size *= dim\n",
    "        self.y = np.empty([size], dtype = x.dtype)\n",
    "    \n",
    "    def eval(self):\n",
    "        self.y = self.x.reshape((self.batch_size, self.y.size))\n",
    "        return self.y\n",
    "\n",
    "\n",
    "class fullconn:\n",
    "    def __init__(self, x, W):\n",
    "        \"\"\"Fully connected layer.\"\"\"\n",
    "        self.x = x\n",
    "        self.W = W\n",
    "    \n",
    "    def eval(self):\n",
    "        return np.matmul(self.x, self.W)\n",
    "    \n",
    "    def ddx(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 90,  96],\n",
       "       [216, 231],\n",
       "       [342, 366]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "b = np.array([[11,12],[14,15],[17,18]])\n",
    "np.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME'):\n",
    "    \"\"\"2D convolution of x with filter W, unit stride.\"\"\"\n",
    "    if padding == 'SAME':\n",
    "        # Pad rows and columns of x with zeros so that dim(x) is unchanged.\n",
    "        new_x_shape = x.shape\n",
    "        pad_ncols = W.shape[0] + (strides[1] - 1) * x.shape[1]\n",
    "        pad_nrows = W.shape[1] + (strides[2] - 1) * x.shape[2]\n",
    "        x_pad = np.pad(x, [(0, 0), (0, pad_ncols), (0, pad_nrows), (0, 0)], mode='constant')\n",
    "    elif padding == 'VALID':\n",
    "        new_x_shape = [x.shape[0], 1 + ((x.shape[1] - W.shape[0]) / strides[1]), 1 + ((x.shape[2] - W.shape[1]) / strides[2]), x.shape[3]]\n",
    "        x_pad = np.resize(x, new_x_shape)\n",
    "    # Slide filter W across x and perform convolution.\n",
    "    conv2d_output = np.empty(new_x_shape[:-1] + W.shape[-1:], dtype = x.dtype)\n",
    "    batch_size, nrows, ncols, out_channels = conv2d_output.shape\n",
    "    for b in range(batch_size):\n",
    "        for i in range(nrows):\n",
    "            stride_i = strides[1] * i\n",
    "            if stride_i + W.shape[0] > x_pad.shape[1]:\n",
    "                break\n",
    "            for j in range(ncols):\n",
    "                stride_j = strides[2] * j\n",
    "                if stride_j + W.shape[1] > x_pad.shape[2]:\n",
    "                    break\n",
    "                for out_c in range(out_channels):\n",
    "                    conv2d_output[b, i, j, out_c] = (x_pad[b, stride_i:stride_i + W.shape[0], stride_j:stride_j + W.shape[1], :] * W[::-1, ::-1, :, out_c]).sum()\n",
    "    return conv2d_output\n",
    "\n",
    "def d_conv2d_dx(x, W, inds1, inds2, strides=[1, 1, 1, 1]):\n",
    "    new_x_shape = [strides[1] * x.shape[1] + W.shape[0], strides[2] * x.shape[2] + W.shape[1], W.shape[2]]\n",
    "    result = np.empty([x.shape[0]] + new_x_shape + list(x.shape[1:]), dtype = np.float32)\n",
    "    for batch in range(x.shape[0]):\n",
    "        for new_x_inds in product(*[range(i) for i in new_x_shape]):\n",
    "            result_inds = tuple([batch] + list(new_x_inds))\n",
    "            max_ind_0 = W.shape[0] + strides[1] * new_x_inds[0]\n",
    "            max_ind_1 = W.shape[1] + strides[2] * new_x_inds[1]\n",
    "            result[result_inds] = W[max_ind_0:0:-1, max_ind_1:0:-1, :, new_x_inds[2]]\n",
    "    return result\n",
    "\n",
    "def d_conv2d_dw(x, W_shape, inds1, inds2, strides=[1, 1, 1, 1]):\n",
    "    if inds1[3] == inds2[3]:\n",
    "        return 0.\n",
    "    new_ind1 = W_shape[0] + strides[1] * inds1[1] - inds2[0]\n",
    "    new_ind2 = W_shape[1] + strides[2] * inds1[2] - inds2[1]\n",
    "    return x[inds1[0], new_ind1, new_ind2, inds2[2]]\n",
    "\n",
    "def maxpool2x2(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1]):\n",
    "    \"\"\"2x2 max pooling layer with non-overlapping kernel stride.\"\"\"\n",
    "    if padding == 'SAME':\n",
    "        # Pad rows and columns of x with zeros if necessary.\n",
    "        pad_ncols = ksize[1] + (strides[1] - 1) * x.shape[1]\n",
    "        pad_nrows = ksize[2] + (strides[2] - 1) * x.shape[2]\n",
    "        x_pad = np.pad(x, [(0, 0), (0, pad_ncols), (0, pad_nrows), (0, 0)], mode='constant')\n",
    "    elif padding == 'VALID':\n",
    "        x_pad = x\n",
    "    mask = np.zeros(x_pad.shape, dtype = x_pad.dtype)\n",
    "    batch_size, nrows, ncols, out_channels = x.shape\n",
    "    # Slide kernel across x and perform pooling to decrease dim(x).\n",
    "    nrows = ceil(x.shape[1] / strides[1])\n",
    "    ncols = ceil(x.shape[2] / strides[2])\n",
    "    pool_output = np.empty([batch_size, nrows, ncols, out_channels], dtype = x.dtype)\n",
    "    for b in range(batch_size):\n",
    "        for i in range(nrows):\n",
    "            stride_i = strides[1] * i\n",
    "            if stride_i + ksize[1] > x_pad.shape[1]:\n",
    "                break\n",
    "            for j in range(ncols):\n",
    "                stride_j = strides[2] * j\n",
    "                if stride_j + ksize[2] > x_pad.shape[2]:\n",
    "                    break\n",
    "                for out_c in range(out_channels):\n",
    "                    x_block = x_pad[b, stride_i:stride_i + ksize[1], stride_j:stride_j + ksize[2], out_c]\n",
    "                    max_val = x_block.max()\n",
    "                    pool_output[b, i, j, out_c] = max_val\n",
    "                    mask[b, stride_i:stride_i + ksize[1], stride_j:stride_j + ksize[2], out_c] = (x_block == max_val).astype(int)\n",
    "    return pool_output, mask\n",
    "\n",
    "def flatten(x):\n",
    "    \"\"\"Flatten tensor to shape [batch_size, x_height * x_width * in_channels].\"\"\"\n",
    "    size = 1\n",
    "    for dim in x.shape[1:]:\n",
    "        size *= dim\n",
    "    return x.reshape((x.shape[0], size))\n",
    "\n",
    "def fullconn(x, W):\n",
    "    \"\"\"Fully connected layer.\"\"\"\n",
    "    return np.matmul(x, W)\n",
    "\n",
    "def d_fullconn_dx(W, inds1, inds2):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(16), dtype = np.float32).reshape([1, 4, 4, 1])\n",
    "W = np.full((3, 3, 1, 2), 0.5, dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.],\n",
       "         [ 1.],\n",
       "         [ 2.],\n",
       "         [ 3.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 4.],\n",
       "         [ 5.],\n",
       "         [ 6.],\n",
       "         [ 7.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 8.],\n",
       "         [ 9.],\n",
       "         [10.],\n",
       "         [11.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[12.],\n",
       "         [13.],\n",
       "         [14.],\n",
       "         [15.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]],\n",
       "\n",
       "        [[ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.],\n",
       "         [ 0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strides = [1, 1, 1, 1]\n",
    "pad_ncols = (strides[1] - 1) * (x.shape[1] - 1) + (W.shape[0] - 1)\n",
    "pad_nrows = (strides[2] - 1) * (x.shape[2] - 1) + (W.shape[1] - 1)\n",
    "x_pad = np.pad(x, [(0, 0), (0, pad_ncols), (0, pad_nrows), (0, 0)], mode='constant')\n",
    "x_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = conv_2d(x, W)\n",
    "b, mask = max_pool_2x2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.,  7.],\n",
       "       [ 8.,  9., 10., 11.],\n",
       "       [12., 13., 14., 15.]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5],\n",
       "       [0.5, 0.5, 0.5]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[::-1,::-1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.5, 27. , 19.5, 10.5],\n",
       "       [40.5, 45. , 31.5, 16.5],\n",
       "       [33. , 36. , 25. , 13. ],\n",
       "       [19.5, 21. , 14.5,  7.5]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45. , 31.5],\n",
       "       [36. , 25. ]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [0., 1., 1., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0. ,  0. ],\n",
       "         [ 0. ,  0. ],\n",
       "         [ 0. ,  0. ],\n",
       "         [ 0. ,  0. ]],\n",
       "\n",
       "        [[ 0. ,  0. ],\n",
       "         [45. , 45. ],\n",
       "         [31.5, 31.5],\n",
       "         [ 0. ,  0. ]],\n",
       "\n",
       "        [[ 0. ,  0. ],\n",
       "         [36. , 36. ],\n",
       "         [25. , 25. ],\n",
       "         [ 0. ,  0. ]],\n",
       "\n",
       "        [[ 0. ,  0. ],\n",
       "         [ 0. ,  0. ],\n",
       "         [ 0. ,  0. ],\n",
       "         [ 0. ,  0. ]]]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a*mask\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0. ],\n",
       "         [ 0. ],\n",
       "         [ 0. ],\n",
       "         [ 0. ]],\n",
       "\n",
       "        [[ 0. ],\n",
       "         [ 0. ],\n",
       "         [ 0. ],\n",
       "         [ 0. ]],\n",
       "\n",
       "        [[ 0. ],\n",
       "         [ 0. ],\n",
       "         [45. ],\n",
       "         [45. ]],\n",
       "\n",
       "        [[31.5],\n",
       "         [31.5],\n",
       "         [ 0. ],\n",
       "         [ 0. ]]]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.resize(c, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[45. , 45. ],\n",
       "         [31.5, 31.5]],\n",
       "\n",
       "        [[36. , 36. ],\n",
       "         [25. , 25. ]]]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 4, 2)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 2, 2)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1100.0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape[0]/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.181818181818183"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(20000*50)/mnist.train.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(range(16)).reshape((4,4)).reshape((16,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[23.5, 23.5],\n",
       "         [28. , 28. ],\n",
       "         [20.5, 20.5],\n",
       "         [11.5, 11.5]],\n",
       "\n",
       "        [[41.5, 41.5],\n",
       "         [46. , 46. ],\n",
       "         [32.5, 32.5],\n",
       "         [17.5, 17.5]],\n",
       "\n",
       "        [[34. , 34. ],\n",
       "         [37. , 37. ],\n",
       "         [26. , 26. ],\n",
       "         [14. , 14. ]],\n",
       "\n",
       "        [[20.5, 20.5],\n",
       "         [22. , 22. ],\n",
       "         [15.5, 15.5],\n",
       "         [ 8.5,  8.5]]]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + np.full([2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
