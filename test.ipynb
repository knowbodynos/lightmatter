{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "from itertools import product\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "path = '/tmp/tensorflow/mnist/input_data'\n",
    "mnist = input_data.read_data_sets(path, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(range(5))\n",
    "a[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    class Utils:\n",
    "        def pad(x, ksize, strides, padding='SAME'):\n",
    "            batch_size, in_height, in_width, in_channels = x.shape\n",
    "            k_batch_size, k_height, k_width, k_channels = ksize\n",
    "            if padding == 'SAME':\n",
    "                out_height = ceil(float(in_height) / float(strides[1]))\n",
    "                out_width = ceil(float(in_width) / float(strides[2]))\n",
    "                if (in_height % strides[1] == 0):\n",
    "                    pad_height = max(k_height - strides[1], 0)\n",
    "                else:\n",
    "                    pad_height = max(k_height - (in_height % strides[1]), 0)\n",
    "                if (in_width % strides[2] == 0):\n",
    "                    pad_width = max(k_width - strides[2], 0)\n",
    "                else:\n",
    "                    pad_width = max(k_width - (in_width % strides[2]), 0)\n",
    "                pad_top = pad_height // 2\n",
    "                pad_bottom = pad_height - pad_top\n",
    "                pad_left = pad_width // 2\n",
    "                pad_right = pad_width - pad_left\n",
    "            elif padding == 'VALID':\n",
    "                out_height = ceil(float(in_height - k_height + 1) / float(strides[1]))\n",
    "                out_width = ceil(float(in_width - k_width + 1) / float(strides[2]))\n",
    "                pad_top = 0\n",
    "                pad_bottom = 0\n",
    "                pad_left = 0\n",
    "                pad_right = 0\n",
    "            return pad_top, pad_bottom, pad_left, pad_right, out_height, out_width\n",
    "        \n",
    "        def img_to_col(x, out_height, out_width, filter_height, filter_width, strides):\n",
    "            batch_size = x.shape[0]\n",
    "            in_channels = x.shape[3]\n",
    "            x_col = np.empty((batch_size * out_height * out_width, filter_height * filter_width * in_channels))\n",
    "            for b in range(batch_size):\n",
    "                for i in range(out_height):\n",
    "                    for j in range(out_width):\n",
    "                        row = b * out_height * out_width + i * out_width + j\n",
    "                        for p in range(filter_height):\n",
    "                            for q in range(filter_width):\n",
    "                                for r in range(in_channels):\n",
    "                                    col = p * filter_width * in_channels + q * in_channels + r\n",
    "                                    x_col[row, col] = x[b, strides[1] * i + p, strides[2] * j + q, r]\n",
    "            return x_col\n",
    "        \n",
    "        def col_to_img(x_col, out_height, out_width, in_height, in_width, filter_height, filter_width, strides):\n",
    "            batch_size = x_col.shape[0] // (out_height * out_width)\n",
    "            in_channels = x_col.shape[1] // (filter_height * filter_width)\n",
    "            x = np.empty((batch_size, in_height, in_width, in_channels))\n",
    "            for b in range(batch_size):\n",
    "                for i in range(out_height):\n",
    "                    for j in range(out_width):\n",
    "                        row = b * out_height * out_width + i * out_width + j\n",
    "                        for p in range(filter_height):\n",
    "                            for q in range(filter_width):\n",
    "                                for r in range(in_channels):\n",
    "                                    col = p * filter_width * in_channels + q * in_channels + r\n",
    "                                    x[b, strides[1] * i + p, strides[2] * j + q, r] = x_col[row, col]\n",
    "            return x\n",
    "        \n",
    "        \n",
    "    class Variables:\n",
    "        def weight_variable(shape):\n",
    "            \"\"\"\n",
    "            Initialize weight matrices with truncated normal distribution with standard deviation of 0.1.\n",
    "\n",
    "            In general, shape = [filter_height, filter_width, in_channels, out_channels].\n",
    "            \"\"\"\n",
    "            stddev = 0.1\n",
    "            size = 1\n",
    "            for dim in shape:\n",
    "                size *= dim\n",
    "            return truncnorm.rvs(-2 * stddev, 2 * stddev, size=size).reshape(shape)\n",
    "\n",
    "        def bias_variable(shape):\n",
    "            \"\"\"\n",
    "            Initialize bias vectors with constant value of 0.1.\n",
    "\n",
    "            In general, shape = [out_channels].\n",
    "            \"\"\"\n",
    "            const = 0.1\n",
    "            return np.full(shape, const)\n",
    "    \n",
    "    \n",
    "    class Activations:\n",
    "        class relu:\n",
    "            def __init__(self, z):\n",
    "                \"\"\"Compute the rectified linear unit using z.\"\"\"\n",
    "                self.z = z\n",
    "                self.mask_nonneg = (z >= 0).astype(np.float32)\n",
    "                mask_zero = (z == 0).astype(np.float32)\n",
    "                self.mask = self.mask_nonneg - 0.5 * mask_zero\n",
    "\n",
    "            def out(self):\n",
    "                self.out = self.z * self.mask\n",
    "                return self.out\n",
    "\n",
    "            def grad_z(self, grad_out):\n",
    "                \"\"\"Compute the derivative of the rectified linear unit using z.\"\"\"\n",
    "                self.grad_z = grad_out * self.mask\n",
    "                return self.grad_z\n",
    "\n",
    "\n",
    "        class softmax:\n",
    "            def __init__(self, z):\n",
    "                \"\"\"Compute the softmax of z.\"\"\"\n",
    "                self.z = z\n",
    "                self.e_z = np.exp(z - z.max())\n",
    "                self.e_z_sum = self.e_z.reshape((self.e_z.shape[0], -1)).sum(axis = 1)\n",
    "\n",
    "            def out(self):\n",
    "                self.out = (self.e_z.T / self.e_z_sum).T\n",
    "                return self.out\n",
    "            \n",
    "            def grad_z(self, grad_out):\n",
    "                \"\"\"Compute the derivative of the softmax of z.\"\"\"\n",
    "                self.grad_z = (grad_out * self.out) - grad_out.dot(np.outer(self.out, self.out))\n",
    "                return self.grad_z\n",
    "    \n",
    "    \n",
    "    class Layers:\n",
    "        class flatten:\n",
    "            def __init__(self, x):\n",
    "                \"\"\"Flatten tensor to shape [batch_size, x_height * x_width * in_channels].\"\"\"\n",
    "                self.x = x\n",
    "\n",
    "            def out(self):\n",
    "                self.out_val = self.x.reshape((self.x.shape[0], -1))\n",
    "                return self.out_val\n",
    "            \n",
    "            def grad_x(self, grad_out):\n",
    "                self.grad_x_val = grad_out.reshape(self.x.shape)\n",
    "                return self.grad_x_val\n",
    "            \n",
    "        \n",
    "        class fullconn:\n",
    "            def __init__(self, x, w):\n",
    "                \"\"\"Fully connected layer.\"\"\"\n",
    "                assert(x.shape[-1] == w.shape[0])\n",
    "                self.x = x\n",
    "                self.w = w\n",
    "                self.batch_size = x.shape[0]\n",
    "                self.in_channels = x.shape[1]\n",
    "                self.out_channels = w.shape[1]\n",
    "\n",
    "            def out(self):\n",
    "                self.out_val = self.x.dot(self.w)\n",
    "                return self.out_val\n",
    "\n",
    "            def grad_x(self, grad_out):\n",
    "                self.grad_x_val = grad_out.dot(self.w.T)\n",
    "                return self.grad_x_val\n",
    "\n",
    "            def grad_w(self, grad_out):\n",
    "                self.grad_w_val = self.x.T.dot(grad_out)\n",
    "                return self.grad_w_val\n",
    "            \n",
    "            \n",
    "        class conv2d:\n",
    "            def __init__(self, x, w, strides=[1, 1, 1, 1], padding='SAME'):\n",
    "                assert(x.shape[3] == w.shape[2])\n",
    "                self.x = x\n",
    "                self.w = w\n",
    "                self.strides = strides\n",
    "                self.batch_size = x.shape[0]\n",
    "                self.in_height = x.shape[1]\n",
    "                self.in_width = x.shape[2]\n",
    "                self.filter_height = w.shape[0]\n",
    "                self.filter_width = w.shape[1]\n",
    "                self.in_channels = w.shape[2]\n",
    "                self.out_channels = w.shape[3]\n",
    "                \n",
    "                ksize = (1, self.filter_height, self.filter_width, 1)\n",
    "                padding_out = NN.Utils.pad(x, ksize, strides, padding = padding)\n",
    "                self.pad_top = padding_out[0]\n",
    "                self.pad_bottom = padding_out[1]\n",
    "                self.pad_left = padding_out[2]\n",
    "                self.pad_right = padding_out[3]\n",
    "                self.out_height = padding_out[4]\n",
    "                self.out_width = padding_out[5]\n",
    "                self.x_pad = np.pad(x, [(0, 0), (self.pad_top, self.pad_bottom), (self.pad_left, self.pad_right), (0, 0)], mode='constant')\n",
    "            \n",
    "            def out_bkp(self):\n",
    "                self.out = np.empty((self.batch_size, self.out_height, self.out_width, self.out_channels))\n",
    "                for b in range(self.batch_size):\n",
    "                    for i in range(self.out_height):\n",
    "                        for j in range(self.out_width):\n",
    "                            for k in range(self.out_channels):\n",
    "                                self.out[b, i, j, k] = (self.x_pad[b, (self.strides[1] * i):(self.strides[1] * i + self.filter_height), (self.strides[2] * j):(self.strides[2] * j + self.filter_width), :] * self.w[::-1, ::-1, :, k]).sum(axis = (0, 1))\n",
    "                return self.out\n",
    "            \n",
    "            def out(self):\n",
    "                x_col = NN.Utils.img_to_col(self.x_pad, self.out_height, self.out_width, self.filter_height, self.filter_width, self.strides)\n",
    "                w_col = self.w[::-1, ::-1].reshape((-1, self.out_channels))\n",
    "                self.fullconn = NN.Layers.fullconn(x_col, w_col)\n",
    "                out_col = self.fullconn.out()\n",
    "                self.out_val = out_col.reshape((self.batch_size, self.out_height, self.out_width, self.out_channels))\n",
    "                return self.out_val\n",
    "            \n",
    "            def grad_x(self, grad_out):\n",
    "                grad_out_reshaped = grad_out.reshape((-1, self.out_channels))\n",
    "                grad_x_col = self.fullconn.grad_x(grad_out_reshaped)\n",
    "                self.grad_x_val = NN.Utils.col_to_img(grad_x_col, self.out_height, self.out_width, self.x_pad.shape[1], self.x_pad.shape[2], self.filter_height, self.filter_width, self.strides)\n",
    "                if self.pad_top > 0:\n",
    "                    self.grad_x_val = self.grad_x_val[:, self.pad_top:, :, :]\n",
    "                if self.pad_bottom > 0:\n",
    "                    self.grad_x_val = self.grad_x_val[:, :-self.pad_bottom, :, :]\n",
    "                if self.pad_left > 0:\n",
    "                    self.grad_x_val = self.grad_x_val[:, :, self.pad_left:, :]\n",
    "                if self.pad_right > 0:\n",
    "                    self.grad_x_val = self.grad_x_val[:, :, :-self.pad_right, :]\n",
    "                return self.grad_x_val\n",
    "\n",
    "            def grad_w(self, grad_out):\n",
    "                grad_out_reshaped = grad_out.reshape((self.batch_size * self.out_height * self.out_width, self.out_channels))\n",
    "                grad_w_col = self.fullconn.grad_w(grad_out_reshaped)\n",
    "                self.grad_w_val = grad_w_col.reshape(self.w.shape)\n",
    "                return self.grad_w_val\n",
    "\n",
    "\n",
    "        class maxpool2d:\n",
    "            def __init__(self, x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME'):\n",
    "                self.x = x\n",
    "                self.ksize = ksize\n",
    "                self.strides = strides\n",
    "                self.batch_size = x.shape[0]\n",
    "                self.in_height = x.shape[1]\n",
    "                self.in_width = x.shape[2]\n",
    "                self.in_channels = x.shape[3]\n",
    "                self.out_channels = self.in_channels\n",
    "                padding_out = NN.Utils.pad(x, ksize, strides, padding = padding)\n",
    "                self.pad_top = padding_out[0]\n",
    "                self.pad_bottom = padding_out[1]\n",
    "                self.pad_left = padding_out[2]\n",
    "                self.pad_right = padding_out[3]\n",
    "                self.out_height = padding_out[4]\n",
    "                self.out_width = padding_out[5]\n",
    "                self.x_pad = np.pad(x, [(0, 0), (self.pad_top, self.pad_bottom), (self.pad_left, self.pad_right), (0, 0)], mode='constant')\n",
    "\n",
    "            def out_bkp(self):\n",
    "                self.out_val = np.empty((self.batch_size, self.out_height, self.out_width, self.out_channels))\n",
    "                self.pos = np.zeros((self.batch_size, self.out_height, self.out_width, self.out_channels, 4), dtype = int)\n",
    "                for b in range(self.batch_size):\n",
    "                    for i in range(self.out_height):\n",
    "                        stride_i = self.strides[1] * i\n",
    "                        for j in range(self.out_width):\n",
    "                            stride_j = self.strides[2] * j\n",
    "                            for k in range(self.out_channels):\n",
    "                                x_block = self.x_pad[b, (self.strides[1] * i):(self.strides[1] * i + self.ksize[1]), (self.strides[2] * j):(self.strides[2] * j + self.ksize[2]), k]\n",
    "                                max_val = x_block.max()\n",
    "                                self.out_val[b, i, j, k] = max_val\n",
    "                                max_inds = list(np.unravel_index(x_block.argmax(), x_block.shape))\n",
    "                                self.pos[b, i, j, k] = np.array([b, self.strides[1] * i + max_inds[0], self.strides[2] * j + max_inds[1], k])\n",
    "                return self.out_val\n",
    "            \n",
    "            def grad_x_bkp(self, grad_out):\n",
    "                self.grad_x_val = np.zeros(self.x_pad.shape)\n",
    "                for b in range(self.batch_size):\n",
    "                    for i in range(self.out_height):\n",
    "                        for j in range(self.out_width):\n",
    "                            for k in range(self.out_channels):\n",
    "                                self.grad_x_val[tuple(self.pos[b, i, j, k])] = grad_out[b, i, j, k]\n",
    "                return self.grad_x_val\n",
    "            \n",
    "            def out(self):\n",
    "                x_reshaped = self.x_pad.transpose((3, 0, 1, 2)).reshape((self.in_channels * self.batch_size, self.in_height, self.in_width, 1))\n",
    "                x_col = NN.Utils.img_to_col(x_reshaped, self.out_height, self.out_width, self.ksize[1], self.ksize[2], self.strides)\n",
    "                self.x_col_maxcols = x_col.argmax(axis = 1)\n",
    "                out_reshaped = x_col[np.arange(x_col.shape[0]), self.x_col_maxcols]\n",
    "                self.out_val = out_reshaped.reshape((self.in_channels, self.batch_size, self.out_height, self.out_width)).transpose((1, 2, 3, 0))\n",
    "                return self.out_val\n",
    "            \n",
    "            def grad_x(self, grad_out):\n",
    "                grad_x_col = np.zeros((self.in_channels * self.batch_size * self.out_height * self.out_width, self.ksize[1] * self.ksize[2]))\n",
    "                grad_x_col[np.arange(grad_x_col.shape[0]), self.x_col_maxcols] = grad_out.transpose((3, 0, 1, 2)).flatten()\n",
    "                grad_x_reshaped = NN.Utils.col_to_img(grad_x_col, self.out_height, self.out_width, self.x_pad.shape[1], self.x_pad.shape[2], self.ksize[1], self.ksize[2], self.strides)\n",
    "                if self.pad_top > 0:\n",
    "                    grad_x_reshaped = grad_x_reshaped[:, self.pad_top:, :, :]\n",
    "                if self.pad_bottom > 0:\n",
    "                    grad_x_reshaped = grad_x_reshaped[:, :-self.pad_bottom, :, :]\n",
    "                if self.pad_left > 0:\n",
    "                    grad_x_reshaped = grad_x_reshaped[:, :, self.pad_left:, :]\n",
    "                if self.pad_right > 0:\n",
    "                    grad_x_reshaped = grad_x_reshaped[:, :, :-self.pad_right, :]\n",
    "                self.grad_x_val = grad_x_reshaped.reshape((self.in_channels, self.batch_size, self.in_height, self.in_width)).transpose((1, 2, 3, 0))\n",
    "                return self.grad_x_val\n",
    "    \n",
    "    \n",
    "    class Cost:\n",
    "        class cross_entropy:\n",
    "            def __init__(self, y_label, y_out):\n",
    "                self.y_label = y_label\n",
    "                self.y_out = y_out\n",
    "            \n",
    "            def out(self):\n",
    "                self.out_val = -np.sum(self.y_label * np.log(self.y_out))\n",
    "                return self.out_val\n",
    "            \n",
    "            def grad_x(self):\n",
    "                self.grad_x_val = -self.y_label / self.y_out\n",
    "                return self.grad_x_val\n",
    "\n",
    "        class softmax_cross_entropy:\n",
    "            def __init__(self, y_label, y_out):\n",
    "                self.y_label = y_label\n",
    "                self.y_out = y_out\n",
    "            \n",
    "            def out(self):\n",
    "                softmax = NN.Activations.softmax(self.y_out)\n",
    "                self.out_val = -np.sum(self.y_label * np.log(softmax.out()))\n",
    "                return self.out_val\n",
    "            \n",
    "            def grad_z(self):\n",
    "                self.grad_z_val = self.y_out - self.y_label\n",
    "                return self.grad_z_val\n",
    "    \n",
    "    \n",
    "    class Metrics:\n",
    "        def accuracy(y_label, y_out):\n",
    "            correct_prediction = np.equal(np.argmax(y_label, axis = 1), np.argmax(y_out, axis = 1))\n",
    "            return correct_prediction.astype(np.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, train_set, x_image_shape=[28, 28]):\n",
    "        self.started = False\n",
    "        self.train_set = train_set\n",
    "        self.epochs_completed = 0\n",
    "        self.x_image_shape = x_image_shape\n",
    "        self.w = []\n",
    "        self.dw = []\n",
    "        self.b = []\n",
    "        self.db = []\n",
    "        self.f = []\n",
    "        self.s = []\n",
    "        \n",
    "    def eval(self, batch_x_images):\n",
    "        # Layer 0 (2D convolution layer)\n",
    "        filter_shape_0 = [5, 5]\n",
    "        in_channels_0 = 1\n",
    "        out_channels_0 = 32\n",
    "\n",
    "        # Reshape input\n",
    "        x_0 = np.reshape(batch_x_images, [batch_x_images.shape[0]] + list(self.x_image_shape) + [in_channels_0])\n",
    "\n",
    "        if not self.started:\n",
    "            self.w.append(NN.Variables.weight_variable(filter_shape_0 + [in_channels_0, out_channels_0]))\n",
    "            self.dw.append(None)\n",
    "            self.b.append(NN.Variables.bias_variable([out_channels_0]))\n",
    "            self.db.append(None)\n",
    "            self.f.append(None)\n",
    "            self.s.append(None)\n",
    "\n",
    "        self.f[0] = NN.Layers.conv2d(x_0, self.w[0])\n",
    "        z_0 = self.f[0].out() + self.b[0]\n",
    "        self.s[0] = NN.Activations.relu(z_0)\n",
    "\n",
    "        y_0 = self.s[0].out()\n",
    "\n",
    "        # Layer 1 (Max pool 2x2)\n",
    "        in_channels_1 = out_channels_0\n",
    "        out_channels_1 = in_channels_1\n",
    "        \n",
    "        if not self.started:\n",
    "            self.w.append(None)\n",
    "            self.dw.append(None)\n",
    "            self.b.append(None)\n",
    "            self.db.append(None)\n",
    "            self.f.append(None)\n",
    "            self.s.append(None)\n",
    "\n",
    "        self.f[1] = NN.Layers.maxpool2d(y_0)\n",
    "\n",
    "        x_1 = self.f[1].out()\n",
    "\n",
    "        # Layer 2 (2D convolution layer)\n",
    "        filter_shape_2 = [5, 5]\n",
    "        in_channels_2 = out_channels_1\n",
    "        out_channels_2 = 64\n",
    "\n",
    "        if not self.started:\n",
    "            self.w.append(NN.Variables.weight_variable(filter_shape_2 + [in_channels_2, out_channels_2]))\n",
    "            self.dw.append(None)\n",
    "            self.b.append(NN.Variables.bias_variable([out_channels_2]))\n",
    "            self.db.append(None)\n",
    "            self.f.append(None)\n",
    "            self.s.append(None)\n",
    "\n",
    "        self.f[2] = NN.Layers.conv2d(x_1, self.w[2])\n",
    "        z_2 = self.f[2].out() + self.b[2]\n",
    "        self.s[2] = NN.Activations.relu(z_2)\n",
    "\n",
    "        x_2 = self.s[2].out()\n",
    "\n",
    "        # Layer 3 (Max pool 2x2)\n",
    "        in_channels_3 = out_channels_2\n",
    "        out_channels_3 = in_channels_3\n",
    "        \n",
    "        if not self.started:\n",
    "            self.w.append(None)\n",
    "            self.dw.append(None)\n",
    "            self.b.append(None)\n",
    "            self.db.append(None)\n",
    "            self.f.append(None)\n",
    "            self.s.append(None)\n",
    "\n",
    "        self.f[3] = NN.Layers.maxpool2d(x_2)\n",
    "\n",
    "        x_3 = self.f[3].out()\n",
    "\n",
    "        # Layer 4 (Flatten)\n",
    "        in_channels_4 = out_channels_3\n",
    "        out_channels_4 = in_channels_4\n",
    "        \n",
    "        if not self.started:\n",
    "            self.w.append(None)\n",
    "            self.dw.append(None)\n",
    "            self.b.append(None)\n",
    "            self.db.append(None)\n",
    "            self.f.append(None)\n",
    "            self.s.append(None)\n",
    "\n",
    "        self.f[4] = NN.Layers.flatten(x_3)\n",
    "\n",
    "        x_4 = self.f[4].out()\n",
    "\n",
    "        # Layer 5 (Fully connected layer)\n",
    "        in_channels_5 = x_4.shape[-1]\n",
    "        out_channels_5 = 1024\n",
    "\n",
    "        if not self.started:\n",
    "            self.w.append(NN.Variables.weight_variable([in_channels_5, out_channels_5]))\n",
    "            self.dw.append(None)\n",
    "            self.b.append(NN.Variables.bias_variable([out_channels_5]))\n",
    "            self.db.append(None)\n",
    "            self.f.append(None)\n",
    "            self.s.append(None)\n",
    "\n",
    "        self.f[5] = NN.Layers.fullconn(x_4, self.w[5])\n",
    "        z_5 = self.f[5].out() + self.b[5]\n",
    "        self.s[5] = NN.Activations.relu(z_5)\n",
    "\n",
    "        x_5 = self.s[5].out()\n",
    "\n",
    "        # Layer 6 (Fully connected layer)\n",
    "        in_channels_6 = out_channels_5\n",
    "        out_channels_6 = 10\n",
    "\n",
    "        if not self.started:\n",
    "            self.w.append(NN.Variables.weight_variable([in_channels_6, out_channels_6]))\n",
    "            self.dw.append(None)\n",
    "            self.b.append(NN.Variables.bias_variable([out_channels_6]))\n",
    "            self.db.append(None)\n",
    "            self.f.append(None)\n",
    "            self.s.append(None)\n",
    "\n",
    "        self.f[6] = NN.Layers.fullconn(x_5, self.w[6])\n",
    "        z_6 = self.f[6].out() + self.b[6]\n",
    "        self.s[6] = NN.Activations.softmax(z_6)\n",
    "\n",
    "        x_6 = self.s[6].out()\n",
    "        \n",
    "        self.batch_y_out = x_6\n",
    "\n",
    "        self.started = True\n",
    "        \n",
    "        return self.batch_y_out\n",
    "    \n",
    "    def backpropagate(self, batch_y_labels, lr = 0.5):\n",
    "        n_layers = len(self.dw)\n",
    "        cost = NN.Cost.softmax_cross_entropy(batch_y_labels, self.batch_y_out)\n",
    "\n",
    "        delta = -lr * cost.grad_z()\n",
    "        if not self.dw[n_layers - 1] is None:\n",
    "            self.db[n_layers - 1] = np.sum(delta, axis = tuple(range(delta.ndim - 1))) / self.batch_size\n",
    "            self.b[n_layers - 1] += self.db[n_layers - 1]\n",
    "            self.dw[n_layers - 1] = self.f[n_layers - 1].grad_w(delta) / self.batch_size\n",
    "            self.w[n_layers - 1] += self.dw[n_layers - 1]\n",
    "        \n",
    "        for i in reversed(range(n_layers - 1)):\n",
    "            if self.dw[i] is None:\n",
    "                delta = self.f[i + 1].grad_x(delta)\n",
    "            else:\n",
    "                delta = self.s[i].grad_z(self.f[i + 1].grad_x(delta))\n",
    "                self.db[i] = np.sum(delta, axis = tuple(range(delta.ndim - 1))) / self.batch_size\n",
    "                self.b[i] += self.db[i]\n",
    "                self.dw[i] = self.f[i].grad_w(delta) / self.batch_size\n",
    "                self.w[i] += self.dw[i]\n",
    "    \n",
    "    def train(self, batch_size, epochs, lr = 0.5):\n",
    "        batch_num = 1\n",
    "        while self.epochs_completed < epochs:\n",
    "            prev_nepoch = self.epochs_completed\n",
    "            batch_x_images, batch_y_labels = self.train_set.next_batch(batch_size)\n",
    "            if self.train_set.epochs_completed > prev_nepoch:\n",
    "                batch_num = 1\n",
    "            batch_y_out = self.eval(batch_x_images)\n",
    "            self.backpropagate(batch_y_labels, lr = lr)\n",
    "            if batch_num % 50 == 0:\n",
    "                batch_accuracy = NN.Metrics.accuracy(batch_y_labels, batch_y_out)\n",
    "                print(\"Epoch: {0}, Batch: {1}, Accuracy: {2:.4f}\".format(self.epochs_completed + 1, batch_num, batch_accuracy))\n",
    "            batch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-430-262b4c8561df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-429-23c5f637fc90>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, batch_size, epochs, lr)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mbatch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mbatch_y_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mbatch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-429-23c5f637fc90>\u001b[0m in \u001b[0;36mbackpropagate\u001b[0;34m(self, lr)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-425-6b804d9da5e0>\u001b[0m in \u001b[0;36mgrad_x\u001b[0;34m(self, grad_out)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mgrad_out_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mgrad_x_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_out_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_x_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_top\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_x_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_top\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-425-6b804d9da5e0>\u001b[0m in \u001b[0;36mcol_to_img\u001b[0;34m(x_col, out_height, out_width, in_height, in_width, filter_height, filter_width, strides)\u001b[0m\n\u001b[1;32m     55\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                                     \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfilter_width\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0min_channels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0min_channels\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                                     \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_col\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.train(50, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mnist.train.images[:3].reshape((3, 28, 28, -1))\n",
    "w = NN.Variables.weight_variable([5, 5, 1, 2])\n",
    "\n",
    "filter_height, filter_width, in_channels, out_channels = w.shape\n",
    "ksize = [1, filter_height, filter_width, 1]\n",
    "strides = [1, 1, 1, 1]\n",
    "padding = 'SAME'\n",
    "pad_top, pad_bottom, pad_left, pad_right, out_height, out_width = NN.Utils.pad(x, ksize, strides=strides, padding=padding)\n",
    "x_pad = np.pad(x, [(0, 0), (pad_top, pad_bottom), (pad_left, pad_right), (0, 0)], mode='constant')\n",
    "\n",
    "batch_size, in_height, in_width, in_channels = x_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_col = w[::-1, ::-1].reshape((-1, out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = np.empty((batch_size * out_height * out_width, filter_height * filter_width * in_channels))\n",
    "for b in range(batch_size):\n",
    "    for i in range(out_height):\n",
    "        for j in range(out_width):\n",
    "            row = b * out_height * out_width + i * out_width + j\n",
    "            for p in range(filter_height):\n",
    "                for q in range(filter_width):\n",
    "                    for r in range(in_channels):\n",
    "                        col = p * filter_width * in_channels + q * in_channels + r\n",
    "                        x_col[row, col] = x_pad[b, strides[1] * i + p, strides[2] * j + q, r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_col = x_col.dot(w_col)\n",
    "out = out_col.reshape((batch_size, out_height, out_width, out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(NN.Layers.conv2d(x, w).out_bkp(), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1],\n",
       "         [ 2,  3]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [ 6,  7]]],\n",
       "\n",
       "\n",
       "       [[[ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15]]]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.array(range(16)).reshape(2,2,2,2)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1],\n",
       "         [ 2,  3]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [ 6,  7]]],\n",
       "\n",
       "\n",
       "       [[[ 8,  9],\n",
       "         [10, 11]],\n",
       "\n",
       "        [[12, 13],\n",
       "         [14, 15]]]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.reshape(-1,2).reshape(2,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(y, x1[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.06827557,  0.16107271,  0.29367168,  0.30623545,\n",
       "        0.34196589,  0.29389756,  0.33536968,  0.33536968,  0.31093111,\n",
       "        0.24768577,  0.18809707,  0.25015544,  0.23430163,  0.24797584,\n",
       "        0.32116464,  0.16368114, -0.0010536 , -0.02712594,  0.06638454,\n",
       "        0.0089785 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.06827557,  0.16107272,  0.29367167,  0.30623546,\n",
       "        0.34196588,  0.29389757,  0.33536968,  0.33536968,  0.31093112,\n",
       "        0.24768578,  0.18809707,  0.25015545,  0.23430163,  0.24797584,\n",
       "        0.32116464,  0.16368115, -0.0010536 , -0.02712595,  0.06638454,\n",
       "        0.0089785 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.Layers.conv2d(x[0], w).eval()[:, :, 0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksize = [1, 2, 2, 1]\n",
    "strides = [1, 2, 2, 1]\n",
    "padding = 'SAME'\n",
    "pad_top, pad_bottom, pad_left, pad_right, out_height, out_width = NN.Utils.pad(x, ksize, strides=strides, padding=padding)\n",
    "x_pad = np.pad(x, [(0, 0), (pad_top, pad_bottom), (pad_left, pad_right), (0, 0)], mode='constant')\n",
    "\n",
    "batch_size, in_height, in_width, in_channels = x_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshaped = x_pad.reshape((batch_size * in_channels, in_height, in_width, 1))\n",
    "x_col = NN.Utils.img_to_col(x_reshaped, out_height, out_width, ksize[1], ksize[2], strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col_maxrows = x_col.argmax(axis = 1)\n",
    "out_reshaped = x_col[np.arange(x_col.shape[0]), x_col_maxrows]\n",
    "out = out_reshaped.reshape((batch_size, out_height, out_width, in_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(NN.Layers.maxpool2d(x).out_bkp(), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_x_col = np.zeros((batch_size * out_height * out_width, ksize[1] * ksize[2] * in_channels))\n",
    "grad_x_col[np.arange(grad_x_col.shape[0]), x_col_maxrows] = out.flatten()\n",
    "grad_x = NN.Utils.col_to_img(grad_x_col, out_height, out_width, in_height, in_width, ksize[1], ksize[2], strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 28, 28, 1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = NN.Layers.maxpool2d(x)\n",
    "b = NN.Layers.maxpool2d(x)\n",
    "np.allclose(a.grad_x_bkp(a.out_bkp()), b.grad_x(b.out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_image_shape = [28, 28]\n",
    "batch_size = 50\n",
    "lr = 0.1\n",
    "started = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "# Layer 0 (2D convolution layer)\n",
    "filter_shape_0 = [5, 5]\n",
    "in_channels_0 = 1\n",
    "out_channels_0 = 32\n",
    "\n",
    "# Reshape input\n",
    "x_0 = np.reshape(batch_xs, [batch_size] + list(x_image_shape) + [in_channels_0])\n",
    "\n",
    "if not started:\n",
    "    w_0 = NN.Variables.weight_variable(filter_shape_0 + [in_channels_0, out_channels_0])\n",
    "    b_0 = NN.Variables.bias_variable([out_channels_0])\n",
    "\n",
    "f_0 = NN.Layers.conv2d(x_0, w_0)\n",
    "z_0 = f_0.out() + b_0\n",
    "s_0 = NN.Activations.relu(z_0)\n",
    "\n",
    "y_0 = s_0.out()\n",
    "\n",
    "# Layer 1 (Max pool 2x2)\n",
    "in_channels_1 = out_channels_0\n",
    "out_channels_1 = in_channels_1\n",
    "\n",
    "f_1 = NN.Layers.maxpool2d(y_0)\n",
    "\n",
    "x_1 = f_1.out()\n",
    "\n",
    "# Layer 2 (2D convolution layer)\n",
    "filter_shape_2 = [5, 5]\n",
    "in_channels_2 = out_channels_1\n",
    "out_channels_2 = 64\n",
    "\n",
    "if not started:\n",
    "    w_2 = NN.Variables.weight_variable(filter_shape_2 + [in_channels_2, out_channels_2])\n",
    "    b_2 = NN.Variables.bias_variable([out_channels_2])\n",
    "\n",
    "f_2 = NN.Layers.conv2d(x_1, w_2)\n",
    "z_2 = f_2.out() + b_2\n",
    "s_2 = NN.Activations.relu(z_2)\n",
    "\n",
    "x_2 = s_2.out()\n",
    "\n",
    "# Layer 3 (Max pool 2x2)\n",
    "in_channels_3 = out_channels_2\n",
    "out_channels_3 = in_channels_3\n",
    "\n",
    "f_3 = NN.Layers.maxpool2d(x_2)\n",
    "\n",
    "x_3 = f_3.out()\n",
    "\n",
    "# Layer 4 (Flatten)\n",
    "in_channels_4 = out_channels_3\n",
    "out_channels_4 = in_channels_4\n",
    "\n",
    "f_4 = NN.Layers.flatten(x_3)\n",
    "\n",
    "x_4 = f_4.out()\n",
    "\n",
    "# Layer 5 (Fully connected layer)\n",
    "in_channels_5 = x_4.shape[-1]\n",
    "out_channels_5 = 1024\n",
    "\n",
    "if not started:\n",
    "    w_5 = NN.Variables.weight_variable([in_channels_5, out_channels_5])\n",
    "    b_5 = NN.Variables.bias_variable([out_channels_5])\n",
    "\n",
    "f_5 = NN.Layers.fullconn(x_4, w_5)\n",
    "z_5 = f_5.out() + b_5\n",
    "s_5 = NN.Activations.relu(z_5)\n",
    "\n",
    "x_5 = s_5.out()\n",
    "\n",
    "# Layer 6 (Fully connected layer)\n",
    "in_channels_6 = out_channels_5\n",
    "out_channels_6 = 10\n",
    "\n",
    "if not started:\n",
    "    w_6 = NN.Variables.weight_variable([in_channels_6, out_channels_6])\n",
    "    b_6 = NN.Variables.bias_variable([out_channels_6])\n",
    "\n",
    "f_6 = NN.Layers.fullconn(x_5, w_6)\n",
    "z_6 = f_6.out() + b_6\n",
    "s_6 = NN.Activations.softmax(z_6)\n",
    "\n",
    "x_6 = s_6.out()\n",
    "\n",
    "started = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.Metrics.accuracy(batch_ys, x_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = NN.Cost.softmax_cross_entropy(batch_ys, x_6)\n",
    "\n",
    "delta_6 = -lr * cost.grad_z()\n",
    "db_6 = np.sum(delta_6, axis = tuple(range(delta_6.ndim - 1))) / batch_size\n",
    "dw_6 = f_6.grad_w(delta_6) / batch_size\n",
    "\n",
    "delta_5 = s_5.grad_z(f_6.grad_x(delta_6))\n",
    "db_5 = np.sum(delta_5, axis = tuple(range(delta_5.ndim - 1))) / batch_size\n",
    "dw_5 = f_5.grad_w(delta_5) / batch_size\n",
    "\n",
    "delta_4 = f_5.grad_x(delta_5)\n",
    "\n",
    "delta_3 = f_4.grad_x(delta_4)\n",
    "\n",
    "delta_2 = s_2.grad_z(f_3.grad_x(delta_3))\n",
    "db_2 = np.sum(delta_2, axis = tuple(range(delta_2.ndim - 1))) / batch_size\n",
    "dw_2 = f_2.grad_w(delta_2) / batch_size\n",
    "\n",
    "delta_1 = f_2.grad_x(delta_2)\n",
    "\n",
    "delta_0 = s_0.grad_z(f_1.grad_x(delta_1))\n",
    "db_0 = np.sum(delta_0, axis = tuple(range(delta_0.ndim - 1))) / batch_size\n",
    "dw_0 = f_0.grad_w(delta_0) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.08770085034859956, 0.03420900676259703)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dw_0.min(), dw_0.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_6 += db_6\n",
    "w_6 += dw_6\n",
    "\n",
    "b_5 += db_5\n",
    "w_5 += dw_5\n",
    "\n",
    "b_2 += db_2\n",
    "w_2 += dw_2\n",
    "\n",
    "b_0 += db_0\n",
    "w_0 += dw_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost = NN.Cost.softmax_cross_entropy(batch_ys, x_6)\n",
    "\n",
    "# delta_6 = -lr * cost.grad_z()\n",
    "# b_6 += np.sum(delta_6, axis = tuple(range(delta_6.ndim - 1))) / batch_size\n",
    "# w_6 += f_6.grad_w(delta_6) / batch_size\n",
    "\n",
    "# delta_5 = s_5.grad_z(f_6.grad_x(delta_6))\n",
    "# b_5 += np.sum(delta_5, axis = tuple(range(delta_5.ndim - 1))) / batch_size\n",
    "# w_5 += f_5.grad_w(delta_5) / batch_size\n",
    "\n",
    "# delta_4 = f_5.grad_x(delta_5)\n",
    "\n",
    "# delta_3 = f_4.grad_x(delta_4)\n",
    "\n",
    "# delta_2 = s_2.grad_z(f_3.grad_x(delta_3))\n",
    "# b_2 += np.sum(delta_2, axis = tuple(range(delta_2.ndim - 1))) / batch_size\n",
    "# w_2 += f_2.grad_w(delta_2) / batch_size\n",
    "\n",
    "# delta_1 = f_2.grad_x(delta_2)\n",
    "\n",
    "# delta_0 = s_0.grad_z(f_1.grad_x(delta_1))\n",
    "# b_0 += np.sum(delta_0, axis = tuple(range(delta_0.ndim - 1))) / batch_size\n",
    "# w_0 += f_0.grad_w(delta_0) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(1024, 10)\n",
      "(1024,)\n",
      "(3136, 1024)\n",
      "(64,)\n",
      "(5, 5, 32, 64)\n",
      "(32,)\n",
      "(5, 5, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "cost = NN.Cost.softmax_cross_entropy(batch_ys, x_6)\n",
    "\n",
    "delta_6 = -lr * cost.grad_z()\n",
    "print(np.sum(delta_6, axis = tuple(range(delta_6.ndim - 1))).shape)\n",
    "print(f_6.grad_w(delta_6).shape)\n",
    "\n",
    "delta_5 = s_5.grad_z(f_6.grad_x(delta_6))\n",
    "print(np.sum(delta_5, axis = tuple(range(delta_5.ndim - 1))).shape)\n",
    "print(f_5.grad_w(delta_5).shape)\n",
    "\n",
    "delta_4 = f_5.grad_x(delta_5)\n",
    "\n",
    "delta_3 = f_4.grad_x(delta_4)\n",
    "\n",
    "delta_2 = s_2.grad_z(f_3.grad_x(delta_3))\n",
    "print(np.sum(delta_2, axis = tuple(range(delta_2.ndim - 1))).shape)\n",
    "print(f_2.grad_w(delta_2).shape)\n",
    "\n",
    "delta_1 = f_2.grad_x(delta_2)\n",
    "\n",
    "delta_0 = s_0.grad_z(f_1.grad_x(delta_1))\n",
    "print(np.sum(delta_0, axis = tuple(range(delta_0.ndim - 1))).shape)\n",
    "print(f_0.grad_w(delta_0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "(5, 1024)\n",
      "(5, 14, 14, 64)\n",
      "(5, 28, 28, 32)\n"
     ]
    }
   ],
   "source": [
    "print(delta_6.shape)\n",
    "print(delta_5.shape)\n",
    "print(delta_2.shape)\n",
    "print(delta_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
